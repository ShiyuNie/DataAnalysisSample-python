




一、 项目背景和介绍
	
	1、 背景
			学习python爬虫技巧，复习python数据处理、分析、可视化，看看目前市场对数据分析人才的要求和需求

	2、 简介
			了解现在求职市场上数据分析师的薪资，以及对数据分析人才的要求和需求，来分析、指导目前可以为数据分析求职做的准备，以及该岗位未来的发展。 本项目利用爬虫爬取拉勾网上数据分析这一岗位的信息，然后进行一些探索和分析。

	3、 目的
	    	了解现在对数据分析师的技能、学历、工作经验的要求，及其对应的薪资
			分析不同地区对数据分析师的需求人数、工作经验和薪资分布；
				不同学历的需求人数和月薪分布；
				不同工作经验的需求人数和月薪分布；
				不同企业规模对数据分析师的需求人数、学历、工作经验和薪资分布；
			以及对数据分析师的技术和其他能力要求的占比。

	4、 数据来源 （2019/04/30）
			本项目数据全部来自拉勾网，是通过python的urllib，request，BeautifulSoup等包从网页上爬取的。
			样本量： 450 个招聘职位。 
			*** 【 样本不多，因此此次分析仅做参考。 】

			选择拉勾网作为数据源主要是因为其岗位信息非常完整规范，极大的减少了前期数据清理和数据整理的工作量。

			爬取主要信息有：
								岗位名称 job_name,
								岗位类型 job_type,
								岗位标签 job_lables,
								公司简称 company_shortname,
								公司全称 company_fullname,
								所在城市 city,
								月薪     salary,
								经验要求 job_experience,
								学历要求 education,
								技能标签 skill_lables,
								需求人数 approve,
								全/兼职  job_status,
								工作地点 work_place,
								职位描述 job_description,
								职位福利 job_advantagelist,
								行业领域 industry_field,
								行业标签 industry_lables,
								公司规模 company_size,
								融资阶段 finance_phase,
								发布时间 release_time


二、 用python里的urllib，request，BeautifulSoup等包，从网页上爬取数据，将数据各个数组存入pandas里dataframe中，并转换为csv文件输出

	详细过程：

		1. 为所需数据各声明一个空数组

		2. 定义读取网页json列表的函数 readlist： 
											先从该网页上查看开发者工具，得到headers、提交的表单、原网址和json文件网址
											按此设定表单，headers用urlencode编码
											requests.Session.post.json得到相应列表
											【time.sleep防反爬虫】

		3. 定义读取网页html内容的函数 readhtml：
											urlib2.Request和urlib2.urlopen.read函数读取网页

		4. 定义一个add函数： 
						用if和isinstance判断是否字符串，若是，则判断长度是否为0，若是则数组存入“Null”字符；
						若不是字符串则用str转换为字符判断。

		5. 定义读取json列表数据的函数 getlistdata：
											根据页码用readlist提取列表
											按网页里的列表里的参数提取对应参数的内容，用for循环
											detail_url = 'https://www.lagou.com/jobs/{}.html'.format(positionId)	# 职位链接
											进行初步整理：
													如拉勾网有firstType、secondType、thirdType表示该职务的分类，将他们合并用-字符连接，定义为职务标签
											将得到的数据用以上add函数存入相应数组（若空值存入‘Null’字符）

		6. 定义读取html中所需内容的函数 gethtmldata：
												用网址detail_url和readhtml提取网页内容
												BeautifulSoup解析，再用.findAll查找对应标签和class或者内容
												.get_text得到文本内容用add函数存入数据

		7. 在main函数里面用for函数让页码从1到30循环读取主网页数据，再套一个小循环读该网页下每个职位的detail—url里面的数据，最后得到所有数据存入pandas.dataframe，用.to_csv输出csv文件。


三、 数据处理和展现

		1. 数据预处理：
		 	读取数据 pd.read_csv 
		 	查看每列数据类型 data.dtypes.value_counts()，查看数据的行列大小 data.shape，查看数据信息 data.info() 
		    查看前三十行数据 data.head(30) 	# 中文需改格式
		    data1.isnull().any() 查看缺失值的列，因工作地点等不重要不作替换或其他处理
			data1.drop_duplicates() 去重
			并在处理之前用 data.copy() 备份

		2. 数据清洗： 
			data1.drop 去除不需要的列
			job_status 去除实习、兼职 【 不关注，且兼职数据太少难以分析 】

		3. 总体：	最大、最小、平均、中位薪资
		   薪资、城市、学历、工作经验、企业规模、技能要求的分布情况： 直方图、饼图
		   各城市、学历、工作经验、企业规模的月薪分布情况： 箱线图、折线图
		   城市对工作经验的需求、企业规模对工作经验、学历的需求： 柱状图
		   职位对各技术要求的占比和月薪情况： 气泡图
		   对于技术和能力要求： 词云图 【 仅做参考 】


四、 结论

		*，样本不多，主要是互联网行业，因此此次分析仅做参考。

		1，北上深广杭 为主要需求数据分析师的城市，占 88.2%，其他城市需求极少。
			15-50、50-150、150-500、500-2000、2000人以上的企业均有需求，其中小企业（15-50人）需求很少，其他企业均有相当的职位需求；参考企业数量，则150人以下的企业平均需求不多，更大企业对数据分析师需求更大。

		2，最大月薪 60.0 k，最小月薪 3.5 k，平均月薪 18.21 k，中位月薪 17.5 k，月薪集中 10-25k；
			其中北京月薪中位数最高且月薪跨度大，广州中位数最小且月薪分布小；
			北京、上海20k以上的职位更多，深广杭10-20k更多；
			企业越大，月薪中位数越高，且50人以上企业月薪集中在 10-30k；
			总体而言，平均薪资比较好，工作1年以上拿到10k以上月薪的机会还是比较大

		3，学历需求以本科为主（占80%以上），硕士、博士需求很少。
			本科以上对月薪没有明显提升；

		4，工作经验1-3、3-5年的需求占绝大部分，3-5年需求最大；
			薪资随工作经验而明显上升，1-3年薪资在10-20k左右，3-5年在20-30k；
			北京、上海、杭州需求更多经验丰富的数据分析师；
			150人规模以下的企业需求更多经验丰富的数据分析师。

		5，能力方面以业务、数据挖掘、经验、用户、团队产品、建模等为主要需求，且偏业务的较多；
			技术方面以SQL、r、python、Excel、SPSS、SAS、BI等为主，SQL（mysql）占 75% 以上为最多，r、python也在50%以上；
			SAS、BI、Hive、Tableau、Python、Hadoop的薪资较高，中位数在 18-20k 左右，相比于其他，oracle和java则薪资较低。


		综上所述： 
				数据分析师总体薪资可观；
				数据分析师基本在 北上深广杭 发展，北上深杭对工作经验丰富的分析师需求更多，应届生可去北京广州；
				小企业可能处于高速发展阶段，需要更多有丰富经验的数据分析师来建设数据体系，而更大规模的企业体系完整、成熟，对数据分析师需求量大且接纳应届生，但总体上市场对经验丰富的分析师需求更大；
				企业对数据分析师的学历要求不高，只要有本科的理论基础，他们更多的看重工作经验丰富、业务娴熟、团队合作等；
				工作经验对薪资有明显提升，企业规模大的月薪也较高；
				市场基本要求分析师掌握SQL（MySQL）、r、python、Excel工具，想要高薪最好掌握SAS、BI、Hive、Tableau、Python、Hadoop等；
				除了技术之外，也应当加强经验的积累、对业务的了解、团队沟通合作能力等等。

